{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image2.png',\n",
       " 'image0.png',\n",
       " 'image3.png',\n",
       " 'image6.jpeg',\n",
       " 'image5.jpg',\n",
       " 'image4.jpg',\n",
       " 'image1.jpg']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "lst_images = os.listdir('../images')\n",
    "lst_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=clip_embeddings)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use chromadb for the same\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient('./db')\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\n",
    "from chromadb.utils.data_loaders import ImageLoader\n",
    "data_loader = ImageLoader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OpenCLIPEmbeddingFunction('ViT-B-16-SigLIP', 'webli')\n",
    "\n",
    "# device='cuda' for GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection('clip_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_or_create_collection(name='clip_embeddings', embedding_function=embedding_function, data_loader=data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "collection.add(\n",
    "    ids=lst_images,\n",
    "    uris=[os.path.join('../images', img) for img in lst_images],\n",
    "    metadatas=[{'image': img} for img in lst_images],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['image0.png',\n",
       "   'image1.jpg',\n",
       "   'image5.jpg',\n",
       "   'image4.jpg',\n",
       "   'image6.jpeg']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[None, None, None, None, None]],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'image': 'image0.png'},\n",
       "   {'image': 'image1.jpg'},\n",
       "   {'image': 'image5.jpg'},\n",
       "   {'image': 'image4.jpg'},\n",
       "   {'image': 'image6.jpeg'}]],\n",
       " 'distances': [[1.801679647785668,\n",
       "   1.966377784601841,\n",
       "   1.974831337251781,\n",
       "   1.982125198556581,\n",
       "   1.9870082452673323]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"a photo of staircase\"],\n",
    "    n_results=5,\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': 'image0.png'},\n",
       " {'image': 'image1.jpg'},\n",
       " {'image': 'image5.jpg'},\n",
       " {'image': 'image4.jpg'},\n",
       " {'image': 'image6.jpeg'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['ids'][0]\n",
    "results['metadatas'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update old image with a new image\n",
    "\n",
    "collection.update(\n",
    "    ids=lst_images[0],\n",
    "    uri=os.path.join('../images', 'staircase.jpg'),\n",
    "    metadata={'image': 'staircase.jpg'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format\n",
    "# {\n",
    "#     '12_34_180': {\n",
    "#         'image_path': '12_34_180.jpg',\n",
    "#         'label': '12_34_180'\n",
    "#     },\n",
    "#     '12_34_270': {\n",
    "#         'image_path': '12_34_270.jpg',\n",
    "#         'label': '12_34_270'\n",
    "#     }\n",
    "# }\n",
    "\n",
    "def store_images(data, collection_name='embeddings'):    \n",
    "    client = chromadb.PersistentClient('./db')\n",
    "    collection = client.get_or_create_collection(name=collection_name, embedding_function=embedding_function, data_loader=data_loader)\n",
    "    collection.add(\n",
    "        ids=data.keys(),        # list of x_y_yaw strings\n",
    "        uris=[node['image_path'] for node in data],\n",
    "        metadatas=[data[node] for node in data]\n",
    "    )\n",
    "    \n",
    "def update_images(new_data, collection_name='embeddings'):\n",
    "    client = chromadb.PersistentClient('./db')\n",
    "    collection = client.get_or_create_collection(name=collection_name, embedding_function=embedding_function, data_loader=data_loader)\n",
    "    for node in new_data:\n",
    "        collection.update(\n",
    "            ids=node,\n",
    "            uri=new_data[node]['image_path'],\n",
    "            metadata=new_data[node]\n",
    "        )\n",
    "        \n",
    "def query_images(query_text, n_results=20, collection_name='embeddings'):\n",
    "    client = chromadb.PersistentClient('./db')\n",
    "    collection = client.get_or_create_collection(name=collection_name, embedding_function=embedding_function, data_loader=data_loader)\n",
    "    results = collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=n_results,\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Configuration\n",
    "IMAGE_FOLDER = \"images_test\"\n",
    "OUTPUT_FOLDER = \"output/\"\n",
    "\n",
    "OPENAI_API_KEY = \"EMPTY\"\n",
    "OPENAI_API_BASE = \"http://0.0.0.0:8080/v1\"\n",
    "MODEL_NAME = \"allenai/Molmo-7B-D-0924\"\n",
    "\n",
    "CONCURRENT_REQUESTS = 10  # Number of concurrent API requests\n",
    "\n",
    "# Prompt Template\n",
    "PROMPT = \"\"\"\n",
    "ONLY ONE IMAGE IS PROVIDED TO YOU. Extract textual features notably height, Depth, Width, Maximum Weight Recommendation, Item Weight, Voltage, Wattage, Item_volume whichever visible STRICTLY.\n",
    "\"\"\"\n",
    "\n",
    "async def fetch(session, semaphore, image_url, index, entity_name):\n",
    "    \"\"\"\n",
    "    Asynchronously fetch the API response for a single image.\n",
    "    \"\"\"\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            payload = {\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"messages\": [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": PROMPT},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "                    ],\n",
    "                }],\n",
    "            }\n",
    "\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "            }\n",
    "\n",
    "            # Set a specific timeout for the request\n",
    "            request_timeout = aiohttp.ClientTimeout(total=5)  # 5-second timeout\n",
    "\n",
    "            async with session.post(f\"{OPENAI_API_BASE}/chat/completions\", json=payload, headers=headers, timeout=request_timeout) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    # Adjust based on actual response structure\n",
    "                    vlm_output = data['choices'][0]['message']['content']\n",
    "                else:\n",
    "                    vlm_output = f\"Error: {response.status}\"\n",
    "        except asyncio.TimeoutError:\n",
    "            vlm_output = \"Timeout Error: Request took longer\"\n",
    "        except Exception as e:\n",
    "            vlm_output = f\"Exception: {str(e)}\"\n",
    "\n",
    "        return {\n",
    "            'index': int(index),\n",
    "            'entity_name': entity_name,\n",
    "            'vlm_output': vlm_output\n",
    "        }\n",
    "\n",
    "async def process_images(session, semaphore, images, start_idx):\n",
    "    \"\"\"\n",
    "    Process a list of images asynchronously.\n",
    "    \"\"\"\n",
    "    tasks = []\n",
    "    for i, image_url in enumerate(images):\n",
    "        idx = start_idx + i\n",
    "        entity_name = df_test.at[idx, 'entity_name']\n",
    "        tasks.append(fetch(session, semaphore, image_url, df_test.at[idx, 'index'], entity_name))\n",
    "    \n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "async def main_async():\n",
    "    \"\"\"\n",
    "    Main asynchronous function to process all images.\n",
    "    \"\"\"\n",
    "    semaphore = asyncio.Semaphore(CONCURRENT_REQUESTS)\n",
    "    connector = aiohttp.TCPConnector(limit=CONCURRENT_REQUESTS)\n",
    "    timeout = aiohttp.ClientTimeout(total=None)  # Adjust timeout as needed\n",
    "\n",
    "    cumulative_results = []\n",
    "    batch_counter = 1\n",
    "\n",
    "    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:\n",
    "        for start in tqdm_asyncio(range(0, len(image_paths), BATCH_SIZE), desc=\"Processing Batches\"):\n",
    "            end = min(start + BATCH_SIZE, len(image_paths))\n",
    "            batch_images = image_paths[start:end]\n",
    "            batch_results = await process_images(session, semaphore, batch_images, start)\n",
    "\n",
    "            cumulative_results.extend(batch_results)\n",
    "\n",
    "            # Write to file\n",
    "            output_path = os.path.join(OUTPUT_FOLDER, f'batch_output_{batch_counter}.json')\n",
    "            with open(output_path, 'w') as outfile:\n",
    "                json.dump(batch_results, outfile, indent=4)\n",
    "            \n",
    "            print(f\"----- Batch {batch_counter} saved with {len(batch_results)} results. -----\")\n",
    "            batch_counter += 1\n",
    "\n",
    "            # Clear memory\n",
    "            cumulative_results = []\n",
    "            gc.collect()\n",
    "\n",
    "    print(\"All batches processed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main_async())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps2_mid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
