{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image2.png',\n",
       " 'image0.png',\n",
       " 'image3.png',\n",
       " 'image6.jpeg',\n",
       " 'image5.jpg',\n",
       " 'image4.jpg',\n",
       " 'image1.jpg']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "lst_images = os.listdir('../images')\n",
    "lst_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=clip_embeddings)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use chromadb for the same\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient('./db')\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\n",
    "from chromadb.utils.data_loaders import ImageLoader\n",
    "data_loader = ImageLoader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OpenCLIPEmbeddingFunction('ViT-B-16-SigLIP', 'webli')\n",
    "\n",
    "# device='cuda' for GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection('clip_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_or_create_collection(name='clip_embeddings', embedding_function=embedding_function, data_loader=data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "collection.add(\n",
    "    ids=lst_images,\n",
    "    uris=[os.path.join('../images', img) for img in lst_images],\n",
    "    metadatas=[{'image': img} for img in lst_images],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['image0.png',\n",
       "   'image1.jpg',\n",
       "   'image5.jpg',\n",
       "   'image4.jpg',\n",
       "   'image6.jpeg']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[None, None, None, None, None]],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'image': 'image0.png'},\n",
       "   {'image': 'image1.jpg'},\n",
       "   {'image': 'image5.jpg'},\n",
       "   {'image': 'image4.jpg'},\n",
       "   {'image': 'image6.jpeg'}]],\n",
       " 'distances': [[1.801679647785668,\n",
       "   1.966377784601841,\n",
       "   1.974831337251781,\n",
       "   1.982125198556581,\n",
       "   1.9870082452673323]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"a photo of staircase\"],\n",
    "    n_results=5,\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': 'image0.png'},\n",
       " {'image': 'image1.jpg'},\n",
       " {'image': 'image5.jpg'},\n",
       " {'image': 'image4.jpg'},\n",
       " {'image': 'image6.jpeg'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['ids'][0]\n",
    "results['metadatas'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update old image with a new image\n",
    "\n",
    "collection.update(\n",
    "    ids=lst_images[0],\n",
    "    uri=os.path.join('../images', 'staircase.jpg'),\n",
    "    metadata={'image': 'staircase.jpg'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\n",
    "from chromadb.utils.data_loaders import ImageLoader\n",
    "\n",
    "# format\n",
    "# {\n",
    "#     '12_34_180': {\n",
    "#         'image_path': '12_34_180.jpg',\n",
    "#         'label': '12_34_180'\n",
    "#     },\n",
    "#     '12_34_270': {\n",
    "#         'image_path': '12_34_270.jpg',\n",
    "#         'label': '12_34_270'\n",
    "#     }\n",
    "# }\n",
    "\n",
    "db_client = chromadb.PersistentClient('./db')\n",
    "\n",
    "def store_images(data, collection_name='embeddings'):    \n",
    "    collection = db_client.get_or_create_collection(name=collection_name, embedding_function=embedding_function, data_loader=ImageLoader())\n",
    "    collection.add(\n",
    "        ids=data.keys(),        # list of x_y_yaw strings\n",
    "        uris=[node['image_path'] for node in data],\n",
    "        metadatas=[data[node] for node in data]\n",
    "    )\n",
    "    \n",
    "def update_images(new_data, collection_name='embeddings'):\n",
    "    collection = db_client.get_or_create_collection(name=collection_name, embedding_function=embedding_function, data_loader=ImageLoader())\n",
    "    for node in new_data:\n",
    "        collection.update(\n",
    "            ids=node,\n",
    "            uri=new_data[node]['image_path'],\n",
    "            metadata=new_data[node]\n",
    "        )\n",
    "        \n",
    "def query_images(query_text, n_results=20, collection_name='embeddings'):\n",
    "    collection = db_client.get_or_create_collection(name=collection_name, embedding_function=embedding_function, data_loader=ImageLoader())\n",
    "    results = collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=n_results,\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import os\n",
    "import gc\n",
    "import requests\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = \"EMPTY\"\n",
    "OPENAI_API_BASE = \"http://0.0.0.0:8000/v1\"\n",
    "MODEL_NAME = \"allenai/Molmo-7B-D-0924\"\n",
    "CONCURRENT_REQUESTS = 10  # Number of concurrent API requests\n",
    "BATCH_SIZE = 10  # Number of images to process in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_text_query(text_prompt, timeout=5):\n",
    "    # For 1 text query, return the output of the VLM\n",
    "    # Send the prompt to the API and get the results\n",
    "    try:\n",
    "        payload = {\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"messages\": [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": text_prompt},\n",
    "                ],\n",
    "            }],\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "\n",
    "        # Set a specific timeout for the request\n",
    "        response = requests.post(f\"{OPENAI_API_BASE}/chat/completions\", json=payload, headers=headers, timeout=timeout)\n",
    "        data = response.json()\n",
    "        \n",
    "        ic(response.status_code)\n",
    "        ic(data)\n",
    "        \n",
    "        vlm_output = data['choices'][0]['message']['content']\n",
    "    \n",
    "    except Exception as e:\n",
    "        vlm_output = f\"Exception: {str(e)}\"\n",
    "\n",
    "    return vlm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| response.status_code: 200\n",
      "ic| data: {'choices': [{'finish_reason': 'stop',\n",
      "                        'index': 0,\n",
      "                        'logprobs': None,\n",
      "                        'message': {'content': \" Hello! I'm here to assist you with any \"\n",
      "                                               'questions or tasks you might have. What '\n",
      "                                               'can I help you with today?',\n",
      "                                    'role': 'assistant',\n",
      "                                    'tool_calls': []},\n",
      "                        'stop_reason': None}],\n",
      "           'created': 1733258623,\n",
      "           'id': 'chatcmpl-234ab4e781d14ff3ba2cd96744915530',\n",
      "           'model': 'allenai/Molmo-7B-D-0924',\n",
      "           'object': 'chat.completion',\n",
      "           'prompt_logprobs': None,\n",
      "           'usage': {'completion_tokens': 26,\n",
      "                     'prompt_tokens': 6,\n",
      "                     'prompt_tokens_details': None,\n",
      "                     'total_tokens': 32}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello! I'm here to assist you with any questions or tasks you might have. What can I help you with today?\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_text_query(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' There are none.',\n",
       " ' Counting the <points x1=\"71.5\" y1=\"91.3\" x2=\"74.6\" y2=\"77.6\" x3=\"80.0\" y3=\"78.1\" x4=\"81.0\" y4=\"89.5\" x5=\"90.5\" y5=\"87.3\" alt=\"no of cardboard cartons or boxes if any\">no of cardboard cartons or boxes if any</points> shows a total of 5.',\n",
       " ' There are none.',\n",
       " ' Counting the <points x1=\"46.8\" y1=\"32.9\" x2=\"47.2\" y2=\"36.4\" x3=\"47.3\" y3=\"30.6\" x4=\"47.6\" y4=\"28.4\" x5=\"49.2\" y5=\"29.6\" x6=\"49.2\" y6=\"40.5\" x7=\"49.8\" y7=\"35.9\" x8=\"51.2\" y8=\"41.4\" x9=\"52.0\" y9=\"36.2\" x10=\"52.4\" y10=\"41.1\" x11=\"53.3\" y11=\"36.2\" x12=\"53.8\" y12=\"33.6\" x13=\"56.6\" y13=\"39.6\" x14=\"58.4\" y14=\"43.8\" x15=\"58.8\" y15=\"39.6\" x16=\"59.6\" y16=\"44.8\" x17=\"59.9\" y17=\"40.5\" x18=\"60.7\" y18=\"45.3\" x19=\"61.3\" y19=\"40.2\" x20=\"62.2\" y20=\"45.0\" alt=\"no of cardboard cartons or boxes if any\">no of cardboard cartons or boxes if any</points> shows a total of 20.',\n",
       " 'Timeout Error: Request took longer',\n",
       " 'Timeout Error: Request took longer',\n",
       " 'Timeout Error: Request took longer']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from .vlm import run_multiple_image_query\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "def multiple_image_query(prompt, image_dir):\n",
    "    results = asyncio.run(run_multiple_image_query(image_dir, prompt))\n",
    "    return results\n",
    "\n",
    "multiple_image_query(\"count no of cardboard cartons or boxes if any\", '../images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_points(text):\n",
    "    # Parse the <points> tag and extract relevant data\n",
    "    match = re.search(r'<points([^>]*)>(.*?)</points>', text)\n",
    "    if not match:\n",
    "        return None\n",
    "\n",
    "    attributes = match.group(1)\n",
    "    main_message = match.group(2)\n",
    "\n",
    "    # Extract the coordinates\n",
    "    x_coords = []\n",
    "    y_coords = []\n",
    "    alt_message = None\n",
    "\n",
    "    # Parse the attributes of the points tag\n",
    "    for attr in attributes.split():\n",
    "        if attr.startswith('x'):\n",
    "            x_coords.append(float(attr.split('=')[1].strip('\"')))\n",
    "        elif attr.startswith('y'):\n",
    "            y_coords.append(float(attr.split('=')[1].strip('\"')))\n",
    "        elif attr.startswith('alt'):\n",
    "            alt_message = re.search(r'alt=\"([^\"]*)\"', attributes).group(1)\n",
    "\n",
    "    return {\n",
    "        \"x_coordinates\": x_coords,\n",
    "        \"y_coordinates\": y_coords,\n",
    "        \"alt_message\": alt_message,\n",
    "        \"main_message\": main_message\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_text = 'so this is <points x1=\"14.4\" y1=\"63.5\" x2=\"44.7\" y2=\"31.4\" x3=\"44.9\" y3=\"70.2\" x4=\"58.4\" y4=\"68.7\" x5=\"63.2\" y5=\"29.9\" x6=\"86.3\" y6=\"59.8\" x7=\"94.4\" y7=\"84.1\" x8=\"98.0\" y8=\"93.6\" alt=\"all main objects in the image\">all main objects in the image</points> and that is the answer'\n",
    "\n",
    "result = extract_points(input_text)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps2_mid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
